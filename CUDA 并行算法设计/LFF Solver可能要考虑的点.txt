1：当点的计算数量很少的时候，线性拟合预测的区间可以不做交并，直接预测就可以了，这点上可以更加激进点
   这一点，我有点小的想法，
   1）在小的计算部分（比如开始计算的时候，完全可以做一次随机撒点猜测
   或者线性拟合区间直接预测），开始时期比较激进
   2）规模到一定程度使用线性拟合制导的所有流程，这样制导更加精确

2：向远处跳的问题：线性拟合可能一直集中于某一个区间的计算，怎么考虑把计算方向引导到远方？
   1）我想通过实验来观察
   2）收集零点，或者有计划的每一次迭代向外走

3：关于使用编码来去掉分支，减少的分支预测的时间和增加的计算的时间的均衡？
   实验来验证

4：假设计算量很大，我们是把所有的点的运行时刻值计算交给约束依次计算（一个约束一个的去计算），
还是每一次把一部分点交给所有的约束同时计算，然后逐步的计算完所有的点，二者的区别和联系是什么？

	我的想法是把任务交给每一个子任务去做，所有的约束都先做一部分数据，直到所有的任务做完，
	这样可以利用GPU的异步机制来提高设备的利用率，
	
5: 关于设备利用率的问题，可以同时启动多个核函数，同时开启多个并行任务去计算，我们可以通过控制
每一次发放的任务计算量来间接控制SM的使用率，虽然没有办法指定SM去完成某一项的任务，但是可以同时
发射多个并行任务来抢占可能空闲的SM（具体哪些是空闲的是硬件透明的）


6:为什么非得用GPU而不采用CPU来做并行化呢？数据的精度与计算速度的相对考虑？精度问题的确定
  我的看法：1）为什么GPU可以？
            我们做的运算设计的都是基本的数学函数的计算，这个GPU是有专门的硬件支持
            线性拟合也只是做一个乘法的计算，计算并不复杂，完全可以放到GPU来做
            对于数据精度我们这里有要求，但是CUDA是支持double和float的类型数据去做计算，所以我们这里可以用GPU去做，
            我做过一下小的实验，在大规模数据的线性拟合计算下，GPU计算加速很明显


7:静态约束分析的过程中应注意做一下区间的预处理，这个应该分为两部分
1）可以直接预测区间的部分，比如sqrt(x)
2) 不可以直接预测区间的部分，不如嵌套的复杂约束，这个在运行时刻把触发Nan和Inf的直接去掉

8:可能存在一种很坏的情况：包括ZY的工具，串行版本LFF Solver，要是只是去一个黄金分割点，可能出现所有的预测解都是非法的，
一旦出现这种情况，当前的搜索就会一直空转，陷入死循环，这个死循环是走不出来的，当然这种情况很少出现，但是这个是一个隐藏很深的bug，





